{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93338c16-fc33-4765-9aba-4622c363a8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importations essentielles\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# Suppression des warnings inutiles\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "\n",
    "print(\"Jupyter Notebook est bien configur√© ! üöÄ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a539f5d-962d-46fc-8c3d-a0a50bf28532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le dataset\n",
    "df = pd.read_csv(\"train.csv\") \n",
    "\n",
    "# Aper√ßu des donn√©es\n",
    "print(df.head())\n",
    "\n",
    "# Informations g√©n√©rales sur les colonnes\n",
    "print(df.info())\n",
    "\n",
    "# Statistiques sur les variables num√©riques\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef34527e-f72f-4293-a59c-afd10cc8c294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# V√©rifier combien de colonnes ont des valeurs manquantes\n",
    "missing_values = df.isnull().sum()\n",
    "missing_values = missing_values[missing_values > 0]  # Afficher uniquement les colonnes concern√©es\n",
    "\n",
    "print(\"Colonnes avec valeurs manquantes :\")\n",
    "print(missing_values.sort_values(ascending=False))\n",
    "\n",
    "# Visualiser les valeurs manquantes avec seaborn\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(df.isnull(), cmap=\"viridis\", cbar=False, yticklabels=False)\n",
    "plt.title(\"Carte des valeurs manquantes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3f75f1-85df-4d5c-81b5-7b8cee8d08d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression des colonnes avec trop de valeurs manquantes\n",
    "df = df.drop(columns=[\"PoolQC\", \"MiscFeature\", \"Alley\", \"Fence\"])\n",
    "\n",
    "# Remplacement des NaN pour les variables cat√©goriques (remplace NaN par \"None\")\n",
    "cols_cat = [\"GarageType\", \"GarageFinish\", \"GarageQual\", \"GarageCond\",\n",
    "            \"BsmtQual\", \"BsmtCond\", \"BsmtExposure\", \"BsmtFinType1\", \"BsmtFinType2\",\n",
    "            \"MasVnrType\"]\n",
    "df[cols_cat] = df[cols_cat].fillna(\"None\")\n",
    "\n",
    "# Remplacement des NaN pour les variables num√©riques (remplace NaN par la m√©diane)\n",
    "cols_num = [\"LotFrontage\", \"MasVnrArea\", \"GarageYrBlt\"]\n",
    "for col in cols_num:\n",
    "    df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "# Remplacement des NaN pour Electrical par la valeur la plus fr√©quente\n",
    "df[\"Electrical\"] = df[\"Electrical\"].fillna(df[\"Electrical\"].mode()[0])\n",
    "\n",
    "# Remplacement des NaN pour FireplaceQu (qualit√© de la chemin√©e)\n",
    "df[\"FireplaceQu\"] = df[\"FireplaceQu\"].fillna(\"None\")\n",
    "\n",
    "# V√©rifier qu'il ne reste plus de valeurs manquantes\n",
    "print(\"Valeurs manquantes apr√®s nettoyage :\")\n",
    "print(df.isnull().sum().sum())  # Doit afficher 0 si tout est bien nettoy√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b739c68-1749-4c15-ba6b-1304cd48370d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remplacement des NaN pour FireplaceQu (qualit√© de la chemin√©e)\n",
    "df[\"FireplaceQu\"] = df[\"FireplaceQu\"].fillna(\"None\")\n",
    "\n",
    "print(df.isnull().sum().sum())  # Doit afficher 0 si tout est bien nettoy√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09ee81f-a5a1-4f64-8c3f-8efc88821f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S√©lectionner uniquement les colonnes num√©riques\n",
    "df_numeric = df.select_dtypes(include=[\"number\"])\n",
    "\n",
    "# Calculer la matrice de corr√©lation uniquement sur ces colonnes\n",
    "correlation_matrix = df_numeric.corr()\n",
    "\n",
    "# Trier les variables les plus corr√©l√©es avec SalePrice\n",
    "correlation_with_price = correlation_matrix[\"SalePrice\"].sort_values(ascending=False)\n",
    "\n",
    "# Afficher les 15 variables les plus corr√©l√©es avec SalePrice\n",
    "print(\"Top 15 des variables les plus corr√©l√©es avec SalePrice :\")\n",
    "print(correlation_with_price.head(15))\n",
    "\n",
    "# Visualisation de la heatmap de corr√©lation\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, cmap=\"coolwarm\", annot=False, fmt=\".2f\")\n",
    "plt.title(\"Matrice de corr√©lation des variables num√©riques\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d803d2e-ad47-43ee-9291-a4b8d651cd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [\"MSZoning\", \"Neighborhood\", \"BldgType\", \"HouseStyle\",\n",
    "            \"RoofStyle\", \"Heating\", \"GarageType\", \"SaleCondition\"]\n",
    "\n",
    "# Compter le nombre de cat√©gories uniques pour chaque colonne\n",
    "for col in cat_cols:\n",
    "    print(f\"{col} : {df[col].nunique()} cat√©gories uniques\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c340e0-6267-4033-bfe2-f01496387486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des colonnes cat√©goriques √† encoder\n",
    "cat_cols = [\"MSZoning\", \"Neighborhood\", \"BldgType\", \"HouseStyle\",\n",
    "            \"RoofStyle\", \"Heating\", \"GarageType\", \"SaleCondition\"]\n",
    "\n",
    "# Appliquer l'encodage One-Hot et supprimer la premi√®re colonne de chaque cat√©gorie (drop_first=True)\n",
    "df_encoded = pd.get_dummies(df, columns=cat_cols, drop_first=True)\n",
    "\n",
    "# V√©rifier le nouveau nombre de colonnes\n",
    "print(\"Nombre de colonnes apr√®s encodage :\", df_encoded.shape[1])\n",
    "\n",
    "# Afficher un aper√ßu des nouvelles colonnes\n",
    "print(df_encoded.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40243b41-2831-4e6f-a94f-917b8d8f0132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S√©lectionner uniquement les colonnes num√©riques apr√®s encodage\n",
    "df_numeric = df_encoded.select_dtypes(include=[\"number\"])\n",
    "\n",
    "# Calculer la matrice de corr√©lation\n",
    "correlation_matrix = df_numeric.corr()\n",
    "\n",
    "# Trier les variables les plus corr√©l√©es avec SalePrice\n",
    "correlation_with_price = correlation_matrix[\"SalePrice\"].sort_values(ascending=False)\n",
    "\n",
    "# Afficher les 15 variables les plus corr√©l√©es avec SalePrice\n",
    "print(\"Top 15 des variables les plus corr√©l√©es avec SalePrice :\")\n",
    "print(correlation_with_price.head(15))\n",
    "\n",
    "# Visualisation de la heatmap de corr√©lation\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, cmap=\"coolwarm\", annot=False, fmt=\".2f\")\n",
    "plt.title(\"Matrice de corr√©lation des variables apr√®s encodage\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81402a9-5188-4d5d-8915-f4b3b4a59f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = correlation_matrix\n",
    "\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5162782b-b96a-42c4-8f0b-9e1161b39ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S√©lection des variables les plus pertinentes\n",
    "features = [\"OverallQual\", \"GrLivArea\", \"GarageCars\", \"GarageArea\",\n",
    "            \"TotalBsmtSF\", \"1stFlrSF\", \"FullBath\", \"TotRmsAbvGrd\",\n",
    "            \"YearBuilt\", \"YearRemodAdd\", \"MasVnrArea\", \"Fireplaces\",\n",
    "            \"GarageYrBlt\", \"BsmtFinSF1\"]\n",
    "\n",
    "# Cr√©ation du dataset final avec les variables s√©lectionn√©es\n",
    "X = df_encoded[features]  # Variables explicatives\n",
    "y = df_encoded[\"SalePrice\"]  # Variable cible\n",
    "\n",
    "# Division des donn√©es en entra√Ænement (80%) et test (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Taille de l'ensemble d'entra√Ænement :\", X_train.shape)\n",
    "print(\"Taille de l'ensemble de test :\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145fcd30-21b5-45e6-858b-cd87ad5c05bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiser et entra√Æner le mod√®le\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Pr√©dictions sur l'ensemble de test\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# √âvaluer le mod√®le\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mse ** 0.5\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Afficher les r√©sultats\n",
    "print(f\"Mean Absolute Error (MAE) : {mae}\")\n",
    "print(f\"Mean Squared Error (MSE) : {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE) : {rmse}\")\n",
    "print(f\"R¬≤ Score : {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0ba89b-ec7b-4f44-8b9b-119d3541d15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiser le mod√®le Random Forest\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Entra√Æner le mod√®le sur l'ensemble d'entra√Ænement\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Pr√©dictions sur l'ensemble de test\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# √âvaluer le mod√®le\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "rmse_rf = mse_rf ** 0.5\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "# Afficher les r√©sultats\n",
    "print(f\"Random Forest - Mean Absolute Error (MAE) : {mae_rf}\")\n",
    "print(f\"Random Forest - Mean Squared Error (MSE) : {mse_rf}\")\n",
    "print(f\"Random Forest - Root Mean Squared Error (RMSE) : {rmse_rf}\")\n",
    "print(f\"Random Forest - R¬≤ Score : {r2_rf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc9487e-00e0-4cd5-bd2b-8098be7eb4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R√©cup√©rer l'importance des variables\n",
    "importances = rf_model.feature_importances_\n",
    "\n",
    "# Cr√©er un DataFrame pour les afficher proprement\n",
    "feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': importances})\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Afficher les 10 variables les plus importantes\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=feature_importance_df.Importance[:10], y=feature_importance_df.Feature[:10], palette=\"viridis\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.title(\"Top 10 des variables les plus importantes\")\n",
    "plt.show()\n",
    "\n",
    "# Afficher le classement complet\n",
    "print(feature_importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0c98a7-056f-439f-b528-4596368f3e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©finir la grille de param√®tres √† tester\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],  # Nombre d'arbres\n",
    "    'max_depth': [None, 10, 20],  # Profondeur max des arbres\n",
    "    'min_samples_split': [2, 5, 10],  # Nombre min d‚Äô√©chantillons pour diviser un n≈ìud\n",
    "    'min_samples_leaf': [1, 2, 4]  # Nombre min d‚Äô√©chantillons dans une feuille\n",
    "}\n",
    "\n",
    "# Initialiser le mod√®le\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# GridSearchCV pour tester toutes les combinaisons\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Meilleurs param√®tres trouv√©s\n",
    "print(\"Meilleurs param√®tres :\", grid_search.best_params_)\n",
    "\n",
    "# Tester avec ces param√®tres optimis√©s\n",
    "best_rf = RandomForestRegressor(**grid_search.best_params_, random_state=42)\n",
    "best_rf.fit(X_train, y_train)\n",
    "y_pred_best_rf = best_rf.predict(X_test)\n",
    "\n",
    "# √âvaluer le mod√®le optimis√©\n",
    "r2_best_rf = r2_score(y_test, y_pred_best_rf)\n",
    "print(\"R¬≤ Score apr√®s optimisation :\", r2_best_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e086552c-60ff-4f03-abdd-a122d0bce7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pr√©dictions avec le mod√®le optimis√©\n",
    "y_pred_optimized = best_rf.predict(X_test)\n",
    "\n",
    "# √âvaluation des erreurs\n",
    "mae_optimized = mean_absolute_error(y_test, y_pred_optimized)\n",
    "mse_optimized = mean_squared_error(y_test, y_pred_optimized)\n",
    "rmse_optimized = mse_optimized ** 0.5\n",
    "\n",
    "# Afficher les r√©sultats\n",
    "print(f\"Optimized Random Forest - Mean Absolute Error (MAE) : {mae_optimized}\")\n",
    "print(f\"Optimized Random Forest - Mean Squared Error (MSE) : {mse_optimized}\")\n",
    "print(f\"Optimized Random Forest - Root Mean Squared Error (RMSE) : {rmse_optimized}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43cd422-b712-4a72-bd6e-b173dfe16739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiser le mod√®le XGBoost\n",
    "xgb_model = XGBRegressor(n_estimators=300, learning_rate=0.05, max_depth=6, random_state=42)\n",
    "\n",
    "# Entra√Æner le mod√®le\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Pr√©dictions\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# √âvaluation XGBoost\n",
    "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
    "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
    "rmse_xgb = mse_xgb ** 0.5\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "\n",
    "# Afficher les r√©sultats\n",
    "print(f\"XGBoost - Mean Absolute Error (MAE) : {mae_xgb}\")\n",
    "print(f\"XGBoost - Mean Squared Error (MSE) : {mse_xgb}\")\n",
    "print(f\"XGBoost - Root Mean Squared Error (RMSE) : {rmse_xgb}\")\n",
    "print(f\"XGBoost - R¬≤ Score : {r2_xgb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737c4fcf-4557-43ae-a78f-88e73209e96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©finir une grille d'hyperparam√®tres √† tester\n",
    "param_grid = {\n",
    "    'n_estimators': [200, 300, 400],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 6, 9]\n",
    "}\n",
    "\n",
    "# Cr√©ation du mod√®le XGBoost\n",
    "xgb = XGBRegressor(random_state=42)\n",
    "\n",
    "# GridSearchCV pour tester les combinaisons\n",
    "grid_search_xgb = GridSearchCV(xgb, param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Afficher les meilleurs param√®tres\n",
    "print(\"Meilleurs param√®tres XGBoost :\", grid_search_xgb.best_params_)\n",
    "\n",
    "# Tester avec ces param√®tres optimis√©s\n",
    "best_xgb = XGBRegressor(**grid_search_xgb.best_params_, random_state=42)\n",
    "best_xgb.fit(X_train, y_train)\n",
    "y_pred_best_xgb = best_xgb.predict(X_test)\n",
    "\n",
    "# √âvaluer le mod√®le optimis√©\n",
    "r2_best_xgb = r2_score(y_test, y_pred_best_xgb)\n",
    "print(\"R¬≤ Score apr√®s optimisation de XGBoost :\", r2_best_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d79772-6066-4380-a33e-0ff8b9ba9e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparer pr√©dictions et vraies valeurs\n",
    "errors = np.abs(y_test - y_pred_best_xgb)\n",
    "\n",
    "# Afficher les 10 pires erreurs\n",
    "worst_predictions = pd.DataFrame({\"Actual\": y_test, \"Predicted\": y_pred_best_xgb, \"Error\": errors})\n",
    "worst_predictions = worst_predictions.sort_values(by=\"Error\", ascending=False)\n",
    "print(\"üîç Top 10 des pires erreurs :\")\n",
    "print(worst_predictions.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5595be8e-34a8-43ba-bd3d-40669f00469b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(y_test, y_pred_best_xgb, alpha=0.5)\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], '--', color='red')  # Ligne id√©ale y = x\n",
    "plt.xlabel(\"Prix r√©el ($)\")\n",
    "plt.ylabel(\"Prix pr√©dit ($)\")\n",
    "plt.title(\"üîç Comparaison des pr√©dictions vs prix r√©els\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4980b7ef-6370-4fb1-8190-11db9e069f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(best_xgb, \"xgboost_model.pkl\")\n",
    "print(\"‚úÖ Mod√®le XGBoost sauvegard√© sous 'xgboost_model.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8e6dc6-660d-40bd-896b-ebd893afb1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Maisons √† plus de 500K$ :\", sum(y_train > 500000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535acb1f-27e1-42b1-8586-110ea28e63f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation log du prix\n",
    "y_train_log = np.log(y_train)\n",
    "y_test_log = np.log(y_test)\n",
    "\n",
    "# R√©entra√Æner XGBoost avec les prix transform√©s\n",
    "xgb_log = XGBRegressor(n_estimators=300, learning_rate=0.05, max_depth=3, random_state=42)\n",
    "xgb_log.fit(X_train, y_train_log)\n",
    "y_pred_log = xgb_log.predict(X_test)\n",
    "\n",
    "# Reconvertir les pr√©dictions avec exp()\n",
    "y_pred_final = np.exp(y_pred_log)\n",
    "\n",
    "# Recalculer les erreurs\n",
    "mae_log = mean_absolute_error(y_test, y_pred_final)\n",
    "r2_log = r2_score(y_test, y_pred_final)\n",
    "\n",
    "print(f\"‚úÖ MAE apr√®s transformation log : {mae_log}\")\n",
    "print(f\"‚úÖ R¬≤ Score apr√®s transformation log : {r2_log}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1a8412-3534-430b-a67f-c789eb0cfb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraire les maisons √† plus de 500K$\n",
    "expensive_houses = X_train[y_train > 500000]\n",
    "expensive_prices = y_train[y_train > 500000]\n",
    "\n",
    "# Ajouter ces maisons plusieurs fois dans l'entra√Ænement\n",
    "X_train_balanced = pd.concat([X_train] + [expensive_houses] * 10, axis=0)\n",
    "y_train_balanced = pd.concat([y_train] + [expensive_prices] * 10, axis=0)\n",
    "\n",
    "# R√©entra√Æner XGBoost avec ces nouvelles donn√©es\n",
    "xgb_balanced = XGBRegressor(n_estimators=300, learning_rate=0.05, max_depth=3, random_state=42)\n",
    "xgb_balanced.fit(X_train_balanced, y_train_balanced)\n",
    "y_pred_balanced = xgb_balanced.predict(X_test)\n",
    "\n",
    "# √âvaluer\n",
    "r2_balanced = r2_score(y_test, y_pred_balanced)\n",
    "print(f\"‚úÖ R¬≤ Score apr√®s augmentation des maisons ch√®res : {r2_balanced}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13145fc0-c544-411e-94f6-c1024f25a1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiser le mod√®le\n",
    "catboost_model = CatBoostRegressor(iterations=300, depth=6, learning_rate=0.05, random_seed=42, verbose=0)\n",
    "\n",
    "# Entra√Æner le mod√®le\n",
    "catboost_model.fit(X_train, y_train)\n",
    "\n",
    "# Pr√©dictions\n",
    "y_pred_catboost = catboost_model.predict(X_test)\n",
    "\n",
    "# √âvaluation\n",
    "r2_catboost = r2_score(y_test, y_pred_catboost)\n",
    "print(f\"‚úÖ R¬≤ Score avec CatBoost : {r2_catboost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6e4f0d-1151-48d0-9c57-1b06a9524c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(catboost_model, \"catboost_best_model.pkl\")\n",
    "print(\"‚úÖ Mod√®le CatBoost sauvegard√© sous 'catboost_best_model.pkl'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
